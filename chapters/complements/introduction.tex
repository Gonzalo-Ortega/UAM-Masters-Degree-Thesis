\chapter*{Introduction}
\markboth{Introduction}{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

Topological Data Analysis (TDA) is an emerging field at the intersection of mathematics, statistics, and computer science that leverages tools from algebraic topology to extract robust, interpretable features from complex, high-dimensional data. Traditional data analysis techniques often struggle to capture the intrinsic shape and connectivity of modern datasets—ranging from biological networks and sensor arrays to financial time series and high-dimensional point clouds. TDA addresses this gap by focusing on the topological invariants of data, which provide a mathematically rigorous description of its global structure. Central to this approach is the idea that the ``shape'' of data—characterized by holes, voids, and connected components—reveals critical insights impervious to noise and geometric distortions.

The cornerstone of TDA is persistent homology, a multiscale extension of classical homology. While homology groups capture topological features (e.g., connected components, loops, cavities) of a space at a fixed scale, persistent homology tracks the birth, persistence, and death of these features across a continuum of scales. This process is formalized through filtrations: nested sequences of topological spaces (e.g., simplicial complexes) built from data, parameterized by a scale parameter (e.g., distance thresholds). As the scale evolves, homology groups induce a structure known as a persistence module—an algebraic object encoding how topological features evolve. The Structure Theorem (Chapter \ref{chap:structure}) classifies these modules, decomposing them into elementary interval modules. This decomposition underpins two powerful visual and analytical summaries: barcodes and persistence diagrams.

A fundamental challenge in TDA is ensuring that topological summaries are stable: small perturbations in input data should induce only controlled changes in the output. Stability theorems form the bedrock of reliable applications, guaranteeing that TDA-based inferences are robust to noise, discretization artifacts, and measurement errors. This thesis provides a unified treatment of four pillars of TDA stability:

\begin{itemize}
    \item Interleaving Stability (Chapter \ref{chap:interleaving-stability}): Establishes an isometry between the algebraic interleaving distance for persistence modules and the combinatorial bottleneck distance for barcodes.
    \item Hausdorff Stability (Chapter \ref{chap:hausdorff-stability}): Bounds the bottleneck distance between persistence diagrams of functions by their $L^{\infty}$-distance, crucial for functional data.
    \item Gromov-Hausdorff Stability (Chapter \ref{chapter:gromov-hausdorf-stability}): Extends stability to metric spaces, linking the bottleneck distance of Vietoris–Rips or Čech complexes with the Gromov–Hausdorff distance between spaces.
    \item Vectorization Stability (Chapter \ref{chap:vectorizations}): Proves robustness for practical summaries like persistence landscapes, images, and Euler curves, enabling integration with machine learning workflows (following the results of \cite{bubenik}, \cite{adams}, \cite{dlotko} and \cite{nina}).

\end{itemize}
This work synthesizes foundational results from algebraic topology, category theory, and metric geometry to present a cohesive theoretical framework for TDA. By elucidating the stability properties of topological summaries, we aim to fortify the mathematical foundations of data analysis and empower applications across scientific domains—from understanding protein folding to quantifying shape in high-dimensional datasets. The subsequent chapters develop these ideas rigorously, beginning with the preliminaries of persistent homology and culminating in modern vectorization techniques.